image_norm_mean: ${.train_transform._args_[5].mean}
image_norm_std: ${.train_transform._args_[5].std}

train_transform:
  _target_: torch.nn.Sequential
  _args_:
    - _target_: torchvision.transforms.RandomHorizontalFlip
      p: 0.5
    - _target_: torchvision.transforms.RandomVerticalFlip
      p: 0.5
    - _target_: torchvision.transforms.RandomResizedCrop
      _convert_: 'partial'
      antialias: true
      size: [224]
    - _target_: torchvision.transforms.RandomApply
      _args_:
        - _target_: torch.nn.ModuleList
          modules:
            - _target_: torchvision.transforms.ColorJitter
              hue: 
                _target_: tr_learn.data.transforms.to_tuple
                items: [0.1, 0.2]
              brightness:
                _target_: tr_learn.data.transforms.to_tuple
                items: [0.5, 1.5]
      p: 0.5
    - _target_: tr_learn.data.transforms.convert_dtype
    - _target_: torchvision.transforms.Normalize
      _convert_: 'partial'
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

valid_transform:
  _target_: torch.nn.Sequential
  _args_:
    - _target_: torchvision.transforms.Resize
      _convert_: 'partial'
      antialias: true
      size: [224]
    - _target_: torchvision.transforms.CenterCrop
      size: 224
    - _target_: tr_learn.data.transforms.convert_dtype
    - _target_: torchvision.transforms.Normalize
      _convert_: 'partial'
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
