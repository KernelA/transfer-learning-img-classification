hydra:
  run:
    dir: .
  output_subdir: null

defaults:
  - optimizer: adamw
  - scheduler: step
  - model: plate_cls
  - datamodule: plates_train_valid
  - transforms: resnext
  - logger: wandb
  - loss: bce
  - _self_

datamodule:
  train_load_info:
    batch_size: 10
  valid_load_info:
    batch_size: 64
  predict_load_info:
    transform: ${transforms.valid_transform}

exp_dir: ./exp/cls_training

seed: 172197

trainer:
  _target_: lightning.Trainer
  accelerator: 'gpu'
  precision: '32'
  fast_dev_run: false
  max_epochs: 50
  check_val_every_n_epoch: 1
  log_every_n_steps: 10
  benchmark: true
  inference_mode: true
  logger:
    - ${logger}
  callbacks:
    # - _target_: lightning.pytorch.callbacks.EarlyStopping
    #   monitor: 'Valid/accuracy' 
    #   min_delta: 1.0e-2
    #   patience: 2
    #   mode: 'max'
    - _target_: lightning.pytorch.callbacks.LearningRateMonitor
      logging_interval: 'epoch'
    - _target_: lightning.pytorch.callbacks.ModelCheckpoint
      save_top_k: 2
      mode: 'max'
      monitor: 'Train/accuracy'
      dirpath: ${exp_dir}/checkpoints
      filename: '{epoch}-{Train/accuracy:.2f}'
      save_last: false
      save_weights_only: true
      every_n_epochs: ${...check_val_every_n_epoch}

